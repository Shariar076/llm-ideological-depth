# LLM Ideological Depth
This repository accompanies the study "[Beyond the Surface: Probing the Ideological Depth of Large Language Models](https://arxiv.org/abs/2508.21448)". We investigate how robust and complex large language models’ (LLMs) internal political representations are (their “ideological depth”) by combining two approaches: steerability experiments (prompt engineering and activation steering) and latent feature analysis using Sparse Autoencoders (SAEs). Our code measures a model’s ability to switch viewpoints under prompting and activation steering, and then probes its internal political features via SAEs. We also estimate each model’s latent ideological position using a Multidimensional Item Response Theory (MIRT) model. These analyses reveal that some models have rich ideological feature vocabularies and remain coherent when steered, while others quickly default to refusal when pushed outside their comfort zone.

## Installation and Requirements
The code is written in Python (tested on 3.10+) and relies on common scientific libraries. Ensure you have the following (via pip or conda):
- PyTorch (for model inference and autoencoders)
- transformers (for loading and prompting LLMs)
- numpy, pandas, scikit-learn, matplotlib, seaborn (for data processing and plotting)
- scipy, statsmodels (for IRT and factor analysis)
- jupyterlab (for running the included notebooks)
No specialized hardware beyond a standard GPU is required for inference. (The steering vectors and SAEs can be precomputed and reused.) Download or checkpoint the target LLMs (e.g. llama-3.1-8b-it and gemma-2-9b-it) before running experiments.
## Usage
**Generate Steering Vectors**: Use `run_generate_vector.sh` to compute contrastive activation vectors via SAEs. This runs `generate_sae_caa_vector.py` on the training prompts to produce the steering vectors for each model and ideology.

**Run Steerability Experiments**: Execute `run_main_table.sh` to apply the steering vectors and prompt-based conditions across the test prompts. This yields response data in the `results` directory under various strengths.

**Analyze Results**:  The plot data for vote counts due to steering is generated by running `analyze_votes_count.py`. Plot data for other charts is generated using `curate_prompt_effects.py` and `curate_steering_effects.py`.

**Reproduce Figures**: Run `plot_vote_counts.py` to plot the line graphs showing the vote counts due to steering. Run `ideology_depth_analysis.py` to plot other graphs.

## References
Please cite the associated paper:
Shariar Kabir, Kevin Esterling, and Yue Dong. "[Beyond the Surface: Probing the Ideological Depth of Large Language Models](https://arxiv.org/abs/2508.21448)".
